{
  
    
        "post0": {
            "title": "Fake News Detection",
            "content": ". Fake news is real problem, and a big one too. One of the many downsides of social media is the constant flow of misinformation that pervades the networks. Even the term itself has been overused and obscured to blur the distinction between fact and fiction. As the world becomes more connected, it seems many are choosing to be more connected primarily with others who share their same views, creating an ideal environment for untruths to go unchecked. But fake news isn&#39;t just a political issue. Covid-19 brought with it a whole new arena of conspiracy theories and bogus medical advice. Detecting fake news is essential to stopping the spread of misinformation.   . Data . The data consists of news articles and titles along with date published and subject. It&#39;s divided into 2 separate files, one of real news articles and one of fake news articles.  . . Environment . The model was trained on AWS EC2 using the AMI &quot;Deep Learning Notebook (Python 3, Tensorflow 2, Pytorch 1.3)&quot; This AMI has a quick and easy setup to run notebooks on an instance that has automatic support of GPUs. . Run the cell below to add necessary packages which are not preinstalled to the environment. . # Run this to install packages in deep learning AMI !pip install pandas !pip install matplotlib !pip install seaborn !pip install nltk !pip install sklearn !pip install wordcloud !pip install boto3 . Import packages and load data . # Import packages import numpy as np import pandas as pd import matplotlib import matplotlib.pyplot as plt import seaborn as sns import os import nltk from nltk.corpus import stopwords from sklearn.feature_extraction.text import CountVectorizer from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.preprocessing import LabelBinarizer from nltk.corpus import stopwords from nltk.stem.porter import PorterStemmer from wordcloud import WordCloud,STOPWORDS from nltk.stem import WordNetLemmatizer from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report,confusion_matrix,accuracy_score import keras from keras.models import Sequential from keras.layers import Dense import tensorflow as tf from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau import boto3 import s3fs import re nltk.download(&#39;stopwords&#39;) %matplotlib inline . The following 3 cells copy the data from s3 and read it into dataframes. This is used when working in an EC2 instance for model training. . ! aws s3 cp s3://lp-s3-bucket/Fake.csv ./data . download: s3://lp-s3-bucket/Fake.csv to data/Fake.csv . ! aws s3 cp s3://lp-s3-bucket/True.csv ./data . download: s3://lp-s3-bucket/True.csv to data/True.csv . fake = pd.read_csv(&quot;data/Fake.csv&quot;) true = pd.read_csv(&quot;data/True.csv&quot;) . The following 3 cells reads in the data from a local directory . file_path = %pwd . files = [] for dirname, _, filenames in os.walk(file_path+&quot; data&quot;): for filename in filenames: print(os.path.join(dirname, filename)) files.append(os.path.join(dirname, filename)) . C: Users Loren fake news data Fake.csv Fake.csv C: Users Loren fake news data True.csv True.csv . fake = pd.read_csv(files[0]) true = pd.read_csv(files[1]) . . Exploratory Data Analysis . The data is in two seperate dataframes. So we&#39;ll take a peak at each one then combine them. . print(fake.shape) fake.head() . (23481, 4) . title text subject date . 0 Donald Trump Sends Out Embarrassing New Year’... | Donald Trump just couldn t wish all Americans ... | News | December 31, 2017 | . 1 Drunk Bragging Trump Staffer Started Russian ... | House Intelligence Committee Chairman Devin Nu... | News | December 31, 2017 | . 2 Sheriff David Clarke Becomes An Internet Joke... | On Friday, it was revealed that former Milwauk... | News | December 30, 2017 | . 3 Trump Is So Obsessed He Even Has Obama’s Name... | On Christmas day, Donald Trump announced that ... | News | December 29, 2017 | . 4 Pope Francis Just Called Out Donald Trump Dur... | Pope Francis used his annual Christmas Day mes... | News | December 25, 2017 | . print(true.shape) true.head() . (21417, 4) . title text subject date . 0 As U.S. budget fight looms, Republicans flip t... | WASHINGTON (Reuters) - The head of a conservat... | politicsNews | December 31, 2017 | . 1 U.S. military to accept transgender recruits o... | WASHINGTON (Reuters) - Transgender people will... | politicsNews | December 29, 2017 | . 2 Senior U.S. Republican senator: &#39;Let Mr. Muell... | WASHINGTON (Reuters) - The special counsel inv... | politicsNews | December 31, 2017 | . 3 FBI Russia probe helped by Australian diplomat... | WASHINGTON (Reuters) - Trump campaign adviser ... | politicsNews | December 30, 2017 | . 4 Trump wants Postal Service to charge &#39;much mor... | SEATTLE/WASHINGTON (Reuters) - President Donal... | politicsNews | December 29, 2017 | . Without reading every article we want to explore the data a bit to prevent any potential data leakage. Let&#39;s take a look at a couple of the articles to get an idea of what they contain. . # print real article example true.text[106] . &#39;WASHINGTON (Reuters) - A lawyer nominated by President Donald Trump to serve as a federal judge withdrew from consideration on Monday after video of his Senate confirmation hearing showing him unable to provide answers to rudimentary legal questions went viral last week. Trump accepted Matthew Petersen’s offer to withdraw his nomination as a district court judge in Washington, a White House official said. Petersen, a Republican member of the Federal Election Commission, became the latest of Trump’s judicial nominations to fail as the president seeks to win confirmation of judges who will make the federal judiciary more conservative. “Just because you’ve seen ‘My Cousin Vinny’ doesn’t qualify you to be a federal judge,” Republican Senator John Kennedy, who grilled Petersen during his Dec. 13 confirmation hearing, told WWL-TV, referring to the 1992 comedy film about a novice lawyer. Kennedy, who has been critical of some of Trump’s judicial nominees, asked several basic legal questions that Petersen could not answer. The video was shown on cable news shows and widely viewed on the internet. “While I am honored to have been nominated for this position, it has become clear to me over the past few days that my nomination has become a distraction - and that is not fair to you or your administration,” Petersen wrote in his withdrawal letter to Trump. “I had hoped that my nearly two decades of public service might carry more weight than my two worst minutes on television,” Petersen added. Petersen became the third Trump judicial pick whose nomination foundered in the past week. Republican Senator Chuck Grassley, chairman of the Senate Judiciary Committee, said last week Trump’s nominations of Jeff Mateer and Brett Talley would not move forward. Both had faced criticism for controversial statements. Talley was reported by online magazine Slate as having posted online sympathetic comments about the early history of the Ku Klux Klan (KKK) white supremacist group. He also failed to disclose that his wife works in the White House counsel’s office, which overseas judicial nominations. Mateer ran into trouble over 2015 speeches including one in which he referred to transgender children as being part of “Satan’s plans,” CNN reported. Despite those setbacks, Trump has made significant progress in filling vacancies on the federal courts with conservative judges, including 12 on the important courts of appeal. He also appointed Justice Neil Gorsuch to fill a vacancy on the Supreme Courts, restoring the high court’s conservative majority. &#39; . # plot a wordcloud of the real articles to get an idea of the common words plt.figure(figsize = (20,20)) wc = WordCloud(max_words = 2500 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(&quot; &quot;.join(true.text)) plt.imshow(wc , interpolation = &#39;bilinear&#39;) . &lt;matplotlib.image.AxesImage at 0x1bda168c860&gt; . # print fake article example fake.text[103] . &#39;In the late 1970 s, Alabama Senate Candidate Roy Moore (R- Of Course) would have been in his early 30 s. However, he liked little girls literally. A bombshell report in the Washington Post alleges that Moore, who was 32 in 1979, approached Leigh Corfman in a courthouse. Corfman was 14 at the time. Moore picked the little girl up near her home, drove her to his home in the woods, and proceeded to molest her, according to the story. Now, this is the man who is running for the United States Senate. The thing is, though, Moore s political career should have been over and done with decades ago.You see, according to people who worked with Roy Moore at the time, it was, quote, common knowledge that he liked dating high schoolers. Moore s former colleague Theresa Jones, who was a Deputy District Attorney with Moore at the time, says of the situation: It was common knowledge that Roy dated high school girls, everyone we knew thought it was weird We wondered why someone his age would hang out at high school football games and the mall but you really wouldn t say anything to someone like that. Jones went on to urge others who know firsthand what Roy Moore is like to come forward:Original tweet by Teresa Jones: &#34;I have no doubt these stories [about Roy Moore] have validity.&#34; pic.twitter.com/oPWaeKrS8W Alexander Marquardt (@MarquardtA) November 11, 2017Well, it s honestly not dating when it s a 30-something year old man and little girls. That s pedophilia. We must not conflate the two. Secondly, this is today s Republican Party. This is where we re at- where one of America s two major political parties thinks it s A-OKAY to try and get a pedophile elected to the United States Senate.It really is too bad that more people didn t out Roy Moore as the pedophile that he was all those years ago. Perhaps the American people would not be in the situation we re in right now if they had with this disgusting man on the brink of becoming a United States Senator.Featured image via Scott Olson/Getty Images&#39; . # plot a wordcloud of the fake articles to get an idea of the common words plt.figure(figsize = (20,20)) wc = WordCloud(max_words = 2500 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(&quot; &quot;.join(fake.text)) plt.imshow(wc , interpolation = &#39;bilinear&#39;) . &lt;matplotlib.image.AxesImage at 0x1bd9cf0bf98&gt; . From looking at the head of the two tables it seems like a lot of the real articles start with the word &#39;Reuters&#39;, where the fake articels don&#39;t. Let&#39;s see if this is true. . # count how many times &#39;reuters&#39; occurs in real articles. sum(true.text.str.contains(&#39;reuters&#39;, case=False, regex=True)) . 21378 . # count how many times &#39;reuters&#39; occurs in fake articles. sum(fake.text.str.contains(&#39;reuters&#39;, case=False, regex=True)) . 322 . Since this is so unbalanced it won&#39;t be included in the features to avoid data leakage. . Now we&#39;ll combine the two tables. . # Create a label column before combining. This will be our target variable. true[&#39;label&#39;] = 1 fake[&#39;label&#39;] = 0 . # Lets combine the two into 1 table df = pd.concat([true, fake]) . # let&#39;s create word counts for the titles and text to check for potential data leakage df[&#39;title_count&#39;] = df[&#39;title&#39;].apply(lambda x: len(x.split())) df[&#39;text_count&#39;] = df[&#39;text&#39;].apply(lambda x: len(x.split())) . df.head() . title text subject date label title_count text_count . 0 As U.S. budget fight looms, Republicans flip t... | WASHINGTON (Reuters) - The head of a conservat... | politicsNews | December 31, 2017 | 1 | 10 | 749 | . 1 U.S. military to accept transgender recruits o... | WASHINGTON (Reuters) - Transgender people will... | politicsNews | December 29, 2017 | 1 | 9 | 624 | . 2 Senior U.S. Republican senator: &#39;Let Mr. Muell... | WASHINGTON (Reuters) - The special counsel inv... | politicsNews | December 31, 2017 | 1 | 10 | 457 | . 3 FBI Russia probe helped by Australian diplomat... | WASHINGTON (Reuters) - Trump campaign adviser ... | politicsNews | December 30, 2017 | 1 | 9 | 376 | . 4 Trump wants Postal Service to charge &#39;much mor... | SEATTLE/WASHINGTON (Reuters) - President Donal... | politicsNews | December 29, 2017 | 1 | 11 | 852 | . df.shape . (44898, 7) . # check for any missing values df.isna().sum() . title 0 text 0 subject 0 date 0 label 0 title_count 0 text_count 0 dtype: int64 . #check to see how the text lengths compare df.groupby(&#39;label&#39;)[&#39;text_count&#39;].describe() . count mean std min 25% 50% 75% max . label . 0 23481.0 | 423.197905 | 408.388890 | 0.0 | 240.0 | 363.0 | 506.0 | 8135.0 | . 1 21417.0 | 385.640099 | 274.006204 | 0.0 | 148.0 | 359.0 | 525.0 | 5172.0 | . The fake articles are 38 words longer on average. &#160;Lets see how the two distributions stack up next to each other. . #collapse plt.figure(figsize=(12,6)) fake = df.loc[df.label == 0] true = df.loc[df.label == 1] sns.distplot(true[&#39;text_count&#39;], hist = False, kde = True, kde_kws = {&#39;shade&#39;: True, &#39;linewidth&#39;: 1}, color=&quot;r&quot;) sns.distplot(fake[&#39;text_count&#39;], hist = False, kde = True, kde_kws = {&#39;shade&#39;: True, &#39;linewidth&#39;: 1}, color=&quot;b&quot;) plt.legend([&#39;True&#39;, &#39;Fake&#39;], prop={&#39;size&#39;: 16}) plt.title(&#39;Density Plot of Word Count&#39;) plt.show() . . The True word count has a surprising multimodal distribution but overall there is a lot of overlap. . Let&#39;s take a look at the subject variable. . df.subject.value_counts() . politicsNews 11272 worldnews 10145 News 9050 politics 6841 left-news 4459 Government News 1570 US_News 783 Middle-east 778 Name: subject, dtype: int64 . #collapse # Plot true articles by subject plt.figure(figsize=(12,6)) sns.countplot(x=&#39;subject&#39;, data=true) plt.title(&#39;True Article by Subject&#39;) plt.show() . . #collapse # Plot fake articles by subject plt.figure(figsize=(12,6)) sns.countplot(x=&#39;subject&#39;, data=fake) plt.title(&#39;Fake Article by Subject&#39;) plt.show() . . Here you can see there is a problem with the subject variable. Becuase the true and fake articles do not share any of the same subject labels, it cannot be included in the model. . . Feature Engineering . The text and title will be combined to make up the feature vector. . #Combine text and titles df[&#39;text&#39;] = df[&#39;text&#39;] + &quot; &quot; + df[&#39;title&#39;] . # instantiate the stemmer tool and stopwords list stemmer = PorterStemmer() sw = stopwords.words(&#39;english&#39;) . # add the word &#39;reuers&#39; to the stopwords sw.append(&#39;reuters&#39;) . # Create text preprocessing function def text_cleaner(text): # remove punctuation text = re.sub(r&#39;[^ w s]&#39;,&#39;&#39;,text) # stem words word_list = [] for i in text.split(): if i.strip().lower() not in sw: word = stemmer.stem(i.strip()) word_list.append(word) return &quot; &quot;.join(word_list) . # apply text cleaner to text df.text = df.text.apply(text_cleaner) . # Create train, validation, and test groups for X &amp; y X = df[&quot;text&quot;] y = df[&quot;label&quot;] x, x_test, y, y_test = train_test_split(X, y,test_size=0.2,train_size=0.8) x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.25,train_size =0.75) . # Create feature vector using CountVectorizer cv = CountVectorizer(ngram_range=(1,2)) cv_x_train = cv.fit_transform(x_train) #transformed valid and test set cv_x_valid =cv.transform(x_valid) cv_x_test =cv.transform(x_test) print(&#39;cv_train:&#39;,cv_x_train.shape) print(&#39;cv_valid:&#39;,cv_x_valid.shape) print(&#39;cv_test:&#39;,cv_x_test.shape) . cv_train: (26938, 2605878) cv_valid: (8980, 2605878) cv_test: (8980, 2605878) . Build and train model . # Define model architecture model = Sequential() model.add(Dense(256, activation = &#39;relu&#39; , input_dim = cv_x_train.shape[1])) model.add(Dense(128, activation = &#39;relu&#39;)) model.add(Dense(64, activation = &#39;relu&#39;)) model.add(Dense(32, activation = &#39;relu&#39;)) model.add(Dense(16, activation = &#39;relu&#39;)) model.add(Dense(8, activation = &#39;relu&#39;)) model.add(Dense(units = 1 , activation = &#39;sigmoid&#39;)) . # Compile model with binary crossentropy loss and &#39;adam&#39; optimizer model.compile(optimizer = &#39;adam&#39; , loss = &#39;binary_crossentropy&#39; , metrics = [&#39;accuracy&#39;]) . # define model callbacks lr_reducer = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, patience=12, factor=0.5, verbose=1) tensorboard = TensorBoard(log_dir=&quot;logs&quot;, write_graph=True, write_images=True) early_stopper = EarlyStopping(monitor=&#39;val_loss&#39;, mode=&#39;auto&#39;) checkpoint = ModelCheckpoint(&#39;./models/model.h5&#39;) . # train model training = model.fit(cv_x_train, y_train, validation_data=(cv_x_valid, y_valid), epochs=5, verbose=2) #callbacks=[lr_reducer, tensorboard]) . Train on 26938 samples, validate on 8980 samples Epoch 1/5 - 3440s - loss: 0.0816 - accuracy: 0.9773 - val_loss: 0.0301 - val_accuracy: 0.9920 Epoch 2/5 - 3426s - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0378 - val_accuracy: 0.9903 Epoch 3/5 - 3453s - loss: 9.8351e-04 - accuracy: 0.9999 - val_loss: 0.0502 - val_accuracy: 0.9924 Epoch 4/5 - 3417s - loss: 5.4657e-04 - accuracy: 0.9999 - val_loss: 0.0407 - val_accuracy: 0.9911 Epoch 5/5 - 3418s - loss: 6.1980e-06 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9912 . Save / load model weights . # save model weights and architecture import json from keras.models import model_from_json, load_model #Save Weights + Architecture model.save_weights(&#39;model_weights.h5&#39;) with open(&#39;model_architecture.json&#39;, &#39;w&#39;) as f: f.write(model.to_json()) . #load weights if needed #model.load_weights(&#39;model_weights.h5&#39;) . Model evaluation . #collapse ## Trained model analysis and evaluation f, ax = plt.subplots(2,1, figsize=(10,8)) ax[0].plot(training.history[&#39;loss&#39;]) ax[0].set_title(&#39;Classify fit of Garment: loss&#39;) ax[0].set_xlabel(&#39;Epoch&#39;) ax[0].set_ylabel(&#39;Loss&#39;) # Accuracy ax[1].plot(training.history[&#39;accuracy&#39;]) ax[1].set_title(&#39;Classify fit of Garment: accuracy&#39;) ax[1].set_xlabel(&#39;Epoch&#39;) ax[1].set_ylabel(&#39;Accuracy&#39;) plt.tight_layout() plt.show() . . # evaluate test group score = model.evaluate(cv_x_test, y_test, verbose=1) print(&#39;Test loss:&#39;, score[0]) print(&#39;Test accuracy:&#39;, score[1]) . 8980/8980 [==============================] - 285s 32ms/step Test loss: 0.10148349083824212 Test accuracy: 0.9897550344467163 . The test group accuracy is 99% . pred = model.predict(cv_x_test) for i in range(len(pred)): if(pred[i] &gt; 0.5): pred[i] = 1 else: pred[i] = 0 accuracy_score(pred,y_test) . 0.9897550111358575 . # exacmine precision &amp; recall cv_report = classification_report(y_test,pred,target_names = [&#39;0&#39;,&#39;1&#39;]) print(cv_report) . precision recall f1-score support 0 0.99 0.99 0.99 4737 1 0.99 0.99 0.99 4243 accuracy 0.99 8980 macro avg 0.99 0.99 0.99 8980 weighted avg 0.99 0.99 0.99 8980 . # print confusion matrix cm_cv = confusion_matrix(y_test,pred) cm_cv . array([[4686, 51], [ 41, 4202]]) . # plot confusion matrix cm_cv = pd.DataFrame(cm_cv, index=[0,1], columns=[0,1]) cm_cv.index.name = &#39;Actual&#39; cm_cv.columns.name = &#39;Predicted&#39; . # plot confusion matrix plt.figure(figsize = (10,10)) sns.heatmap(cm_cv,cmap= &quot;Blues&quot;,annot = True, fmt=&#39;&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f57cd20cb90&gt; . Acknowledgements . Ahmed H, Traore I, Saad S. “Detecting opinion spams and fake news using text classification”, Journal of Security and Privacy, Volume 1, Issue 1, Wiley, January/February 2018. Ahmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments. ISDDC 2017. Lecture Notes in Computer Science, vol 10618. Springer, Cham (pp. 127-138). . View on github .",
            "url": "http://www.datastuff.io/nlp/keras/deep%20learning/aws/2020/05/20/fake-news.html",
            "relUrl": "/nlp/keras/deep%20learning/aws/2020/05/20/fake-news.html",
            "date": " • May 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Predicting Customer Churn",
            "content": ". Preventing customer attrition, or churn, is a common business objective. Losing customers results in direct revenue loss, as well as the expenditure of resources to continually find new customers. Brands across all industries are looking for ways to build meaningful bonds with their customers in order to keep them engaged and loyal to the company. In the telecommunications industry, it&#39;s a particularly challenging problem as customers in most markets have access to several options. . The dataset: Telco Customer Churn . The Telco Customer Churn dataset contains customer information from a telecommunications company. It includes general demographic information about the customer as well as the various services they were using. It was published by IBM in 2015. The raw data contains 7043 rows and 21 columns, with each row being a unique customer. The target variable is Churn, whether or not the customer left the company in the last 30 days. . import pandas as pd from matplotlib import pyplot as plt import numpy as np import math import seaborn as sns import sklearn from sklearn import linear_model from sklearn.naive_bayes import BernoulliNB from sklearn import preprocessing from sklearn import tree from sklearn import ensemble from sklearn.ensemble import GradientBoostingClassifier from sklearn.model_selection import cross_val_score from sklearn.linear_model import LogisticRegression from sklearn.grid_search import GridSearchCV from sklearn.svm import SVC from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import confusion_matrix from sklearn.decomposition import PCA from sklearn.model_selection import train_test_split import time %matplotlib inline import warnings warnings.filterwarnings(&#39;ignore&#39;) sns.set(font_scale=1.25) sns.set_style(&#39;white&#39;) . df = pd.read_csv(&#39;WA_Fn-UseC_-Telco-Customer-Churn.csv&#39;) . df.shape . (7043, 21) . df.head() . customerID gender SeniorCitizen Partner Dependents tenure PhoneService MultipleLines InternetService OnlineSecurity ... DeviceProtection TechSupport StreamingTV StreamingMovies Contract PaperlessBilling PaymentMethod MonthlyCharges TotalCharges Churn . 0 7590-VHVEG | Female | 0 | Yes | No | 1 | No | No phone service | DSL | No | ... | No | No | No | No | Month-to-month | Yes | Electronic check | 29.85 | 29.85 | No | . 1 5575-GNVDE | Male | 0 | No | No | 34 | Yes | No | DSL | Yes | ... | Yes | No | No | No | One year | No | Mailed check | 56.95 | 1889.5 | No | . 2 3668-QPYBK | Male | 0 | No | No | 2 | Yes | No | DSL | Yes | ... | No | No | No | No | Month-to-month | Yes | Mailed check | 53.85 | 108.15 | Yes | . 3 7795-CFOCW | Male | 0 | No | No | 45 | No | No phone service | DSL | Yes | ... | Yes | Yes | No | No | One year | No | Bank transfer (automatic) | 42.30 | 1840.75 | No | . 4 9237-HQITU | Female | 0 | No | No | 2 | Yes | No | Fiber optic | No | ... | No | No | No | No | Month-to-month | Yes | Electronic check | 70.70 | 151.65 | Yes | . 5 rows × 21 columns . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 7043 entries, 0 to 7042 Data columns (total 21 columns): customerID 7043 non-null object gender 7043 non-null object SeniorCitizen 7043 non-null int64 Partner 7043 non-null object Dependents 7043 non-null object tenure 7043 non-null int64 PhoneService 7043 non-null object MultipleLines 7043 non-null object InternetService 7043 non-null object OnlineSecurity 7043 non-null object OnlineBackup 7043 non-null object DeviceProtection 7043 non-null object TechSupport 7043 non-null object StreamingTV 7043 non-null object StreamingMovies 7043 non-null object Contract 7043 non-null object PaperlessBilling 7043 non-null object PaymentMethod 7043 non-null object MonthlyCharges 7043 non-null float64 TotalCharges 7043 non-null object Churn 7043 non-null object dtypes: float64(1), int64(2), object(18) memory usage: 1.1+ MB . Data Exploratoration and Cleaning . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;gender&quot;, data=df); plt.title(&#39;Gender&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;SeniorCitizen&quot;, data=df); plt.title(&#39;Senior Citizen&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;Partner&quot;, data=df); plt.title(&#39;Partner&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;Dependents&quot;, data=df); plt.title(&#39;Dependents&#39;) plt.show() . #collapse #number of months customer has been with the company plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) sns.distplot(df[&#39;tenure&#39;]) plt.title(&#39;tenure&#39;) plt.subplot(1, 2, 2) sns.boxplot(df[&#39;tenure&#39;]) plt.title(&#39;tenure&#39;) plt.show() . . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;PhoneService&quot;, data=df); plt.title(&#39;PhoneService&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;MultipleLines&quot;, data=df); plt.title(&#39;MultipleLines&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;InternetService&quot;, data=df); plt.title(&#39;InternetService&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;OnlineSecurity&quot;, data=df); plt.title(&#39;OnlineSecurity&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;OnlineBackup&quot;, data=df); plt.title(&#39;OnlineBackup&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;DeviceProtection&quot;, data=df); plt.title(&#39;DeviceProtection&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;TechSupport&quot;, data=df); plt.title(&#39;TechSupport&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;StreamingTV&quot;, data=df); plt.title(&#39;StreamingTV&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;StreamingMovies&quot;, data=df); plt.title(&#39;StreamingMovies&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;Contract&quot;, data=df); plt.title(&#39;Contract&#39;) plt.show() . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;PaperlessBilling&quot;, data=df); plt.title(&#39;PaperlessBilling&#39;) plt.show() . plt.figure(figsize=(12,4)) sns.countplot(x=&quot;PaymentMethod&quot;, data=df); plt.title(&#39;PaymentMethod&#39;) plt.show() . #collapse plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) sns.distplot(df[&#39;MonthlyCharges&#39;]) plt.title(&#39;MonthlyCharges&#39;) plt.subplot(1, 2, 2) sns.boxplot(df[&#39;MonthlyCharges&#39;]) plt.title(&#39;MonthlyCharges&#39;) plt.show() . . # Total charges is missing some data len(df[df[&#39;TotalCharges&#39;] == &#39; &#39;]) . 11 . # Dropping rows that are missing total charges so we can convert to float df = df[df[&#39;TotalCharges&#39;] != &#39; &#39;] df[&#39;TotalCharges&#39;] = df[&#39;TotalCharges&#39;].astype(&#39;float64&#39;) . #collapse plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) sns.distplot(df[&#39;TotalCharges&#39;]) plt.title(&#39;TotalCharges&#39;) plt.subplot(1, 2, 2) sns.boxplot(df[&#39;TotalCharges&#39;]) plt.title(&#39;TotalCharges&#39;) plt.show() . . Explore the Target variable . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;Churn&quot;, data=df); plt.title(&#39;Churn&#39;) plt.show() . As PhoneService and SeniorCitizen are both very imbalanced variables, I will drop the subsets of customers who are senior citizens or who don&#39;t have phone service. . df = df[df[&#39;SeniorCitizen&#39;] == 0 ] . df = df[df[&#39;PhoneService&#39;] == &#39;Yes&#39; ] . len(df[df[&#39;Churn&#39;] == &#39;Yes&#39;]) . 1267 . len(df[df[&#39;Churn&#39;] == &#39;No&#39;]) / len(df) . 0.7615732028603689 . df.shape . (5314, 21) . To combat the class imbalance of the target variable, the dominant class will be randomly down-sampled to achieve a 50/50 split. . from sklearn.utils import resample # Separate majority and minority classes df_majority = df[df[&#39;Churn&#39;]==&#39;No&#39;] df_minority = df[df[&#39;Churn&#39;]==&#39;Yes&#39;] # Downsample majority class df_majority_downsampled = resample(df_majority, replace=False, # sample without replacement n_samples=1267, # to match minority class random_state=123) # reproducible results # Combine minority class with downsampled majority class df_downsampled = pd.concat([df_majority_downsampled, df_minority]) # Display new class counts df_downsampled.Churn.value_counts() . Yes 1267 No 1267 Name: Churn, dtype: int64 . plt.figure(figsize=(8,4)) sns.countplot(x=&quot;Churn&quot;, data=df_downsampled); plt.title(&#39;Churn&#39;) plt.show() . Benchmark of .5 . Feature Engineering and Selection . #Create dummies df_downsampled = pd.get_dummies(data=df_downsampled, columns=[&#39;gender&#39;, &#39;Partner&#39;, &#39;Dependents&#39;,&#39;MultipleLines&#39;, &#39;InternetService&#39;, &#39;OnlineSecurity&#39;,&#39;OnlineBackup&#39;, &#39;DeviceProtection&#39;, &#39;TechSupport&#39;, &#39;StreamingTV&#39;, &#39;StreamingMovies&#39;, &#39;Contract&#39;, &#39;PaperlessBilling&#39;, &#39;PaymentMethod&#39;], drop_first=True) #Drop variables that won&#39;t affect target X = df_downsampled.drop([&#39;customerID&#39;, &#39;Churn&#39;, &#39;SeniorCitizen&#39;, &#39;PhoneService&#39;], axis=1) df_downsampled[&#39;Churn&#39;] = np.where(df_downsampled[&#39;Churn&#39;] == &#39;No&#39;, 0, 1) y = df_downsampled[&#39;Churn&#39;].values.reshape(-1, 1) . #collapse corrmat = X.corr() # Set up the matplotlib figure. f, ax = plt.subplots(figsize=(12, 12)) # Draw the heatmap using seaborn sns.heatmap(corrmat, vmax=.8, square=True) plt.show() . . Create training and testing split . # create training and testing vars X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) y_test = y_test.flatten() . Modeling . Naive Bayes . start_time = time.clock() # Instantiate and fit model bnb = BernoulliNB() bnb.fit(X, y) #Get Y predictions y_pred = bnb.predict(X) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) # Display our results. print(&quot; nNumber of mislabeled points out of a total {} points : {}&quot;.format( df_downsampled.shape[0], (y_pred != df_downsampled[&#39;Churn&#39;]).sum().sum() )) . Runtime: 0.01 seconds Number of mislabeled points out of a total 2534 points : 714 . cv_score =cross_val_score(bnb, X, y, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.76771654 0.76377953 0.70866142 0.70866142 0.71653543 0.69291339 0.67322835 0.68253968 0.71428571 0.74206349] cross validation mean: 0.7170384951881015 cross validation range: 0.0944881889763779 . bnb = BernoulliNB() bnb.fit(X_train, y_train) y_pred = bnb.predict(X_test) . print(bnb.score(X_test, y_test)) . 0.7161629434954008 . confusion_matrix(y_test, y_pred) . array([[212, 165], [ 51, 333]], dtype=int64) . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 165 Type 2 error (false negative): 51 Sensitivity: 0.8671875 Specificity: 0.5623342175066313 . KNN . #collapse no_neighbors = [] for i in range(1, 200, 2): neighbors = KNeighborsClassifier(n_neighbors=i) neighbors.fit(X,y) score = cross_val_score(neighbors, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() no_neighbors.append([i, mean_score, score_range]) no_neighbors = pd.DataFrame(no_neighbors) no_neighbors.columns = [&#39;k&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(no_neighbors.k, no_neighbors.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;Number of Neighbors&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(no_neighbors.k, no_neighbors.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;Number of Neighbors&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . no_neighbors[no_neighbors[&#39;mean_score&#39;] == no_neighbors[&#39;mean_score&#39;].max()] . k mean_score score_range . 17 35 | 0.733652 | 0.088770 | . 18 37 | 0.733652 | 0.076928 | . neighbors = KNeighborsClassifier(n_neighbors=37) neighbors.fit(X_train,y_train) neighbors.score(X_test,y_test) . 0.7306176084099869 . cv_score =cross_val_score(neighbors, X, y, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.7519685 0.73622047 0.69291339 0.74409449 0.75590551 0.72047244 0.69685039 0.73015873 0.73809524 0.76984127] cross validation mean: 0.7336520434945631 cross validation range: 0.07692788401449824 . #collapse #with distance weighting no_neighbors = [] for i in range(1, 200, 2): neighbors = KNeighborsClassifier(n_neighbors=i, weights=&#39;distance&#39;) neighbors.fit(X,y) score = cross_val_score(neighbors, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() no_neighbors.append([i, mean_score, score_range]) no_neighbors = pd.DataFrame(no_neighbors) no_neighbors.columns = [&#39;k&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(no_neighbors.k, no_neighbors.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;Number of Neighbors&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(no_neighbors.k, no_neighbors.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;Number of Neighbors&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . no_neighbors[no_neighbors[&#39;mean_score&#39;] == no_neighbors[&#39;mean_score&#39;].max()] . k mean_score score_range . 19 39 | 0.730474 | 0.072991 | . no_neighbors[no_neighbors[&#39;score_range&#39;] == no_neighbors[&#39;score_range&#39;].min()] . k mean_score score_range . 26 53 | 0.727722 | 0.059055 | . start_time = time.clock() neighbors = KNeighborsClassifier(n_neighbors=53, weights=&#39;distance&#39;) y_pred = neighbors.fit(X_train,y_train).predict(X_test) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) #confusion matrix confusion_matrix(y_test, y_pred) . Runtime: 0.02 seconds . array([[275, 102], [114, 270]], dtype=int64) . neighbors.score(X_test,y_test) . 0.7161629434954008 . cv_score =cross_val_score(neighbors, X, y, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.74409449 0.72047244 0.7007874 0.73622047 0.75984252 0.70472441 0.70472441 0.71428571 0.73412698 0.75793651] cross validation mean: 0.7277215348081489 cross validation range: 0.05905511811023623 . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 102 Type 2 error (false negative): 114 Sensitivity: 0.703125 Specificity: 0.7294429708222812 . Decision Tree . #collapse #Tuning Max Depth param_tune = [] for i in range(1, 40): decision_tree = tree.DecisionTreeClassifier(criterion=&#39;entropy&#39;, max_depth=i) decision_tree.fit(X, y) score = cross_val_score(decision_tree, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;Max Depth&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;Max Depth&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . param_tune[param_tune[&#39;mean_score&#39;] == param_tune[&#39;mean_score&#39;].max()] . parameter mean_score score_range . 5 6 | 0.76283 | 0.090551 | . #collapse #Tuning Max features param_tune = [] for i in range(1, X.shape[1]): decision_tree = tree.DecisionTreeClassifier(criterion=&#39;entropy&#39;, max_depth=5, max_features=i) decision_tree.fit(X, y) score = cross_val_score(decision_tree, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;Max Features&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;Max Features&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . param_tune[param_tune[&#39;mean_score&#39;] == param_tune[&#39;mean_score&#39;].max()] . parameter mean_score score_range . 20 21 | 0.762811 | 0.082677 | . start_time = time.clock() decision_tree = tree.DecisionTreeClassifier(criterion=&#39;entropy&#39;, max_depth=3, max_features=X.shape[1]) y_pred = decision_tree.fit(X_train, y_train).predict(X_test) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) confusion_matrix(y_test, y_pred) . Runtime: 0.01 seconds . array([[305, 72], [152, 232]], dtype=int64) . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 72 Type 2 error (false negative): 152 Sensitivity: 0.6041666666666666 Specificity: 0.8090185676392573 . cv_score =cross_val_score(decision_tree, X, y, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.78346457 0.7519685 0.72834646 0.68503937 0.72440945 0.67322835 0.70866142 0.70634921 0.74206349 0.72222222] cross validation mean: 0.7225753030871142 cross validation range: 0.11023622047244097 . Random Forest . #collapse #Tune number of estimators param_tune = [] for i in np.arange(10, 100): rfc = ensemble.RandomForestClassifier(n_estimators=i, max_depth=8, max_features=None) rfc.fit(X, y) score = cross_val_score(rfc, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;Number of Estimators&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;Number of Estimators&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . param_tune[param_tune[&#39;mean_score&#39;] == param_tune[&#39;mean_score&#39;].max()] . parameter mean_score score_range . 11 21 | 0.762414 | 0.086614 | . #collapse #Tune max depth param_tune = [] for i in np.arange(1, 20): rfc = ensemble.RandomForestClassifier(n_estimators=38, max_depth=i) rfc.fit(X, y) score = cross_val_score(rfc, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;Max Depth&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;Max Depth&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . param_tune[param_tune[&#39;mean_score&#39;] == param_tune[&#39;mean_score&#39;].max()] . parameter mean_score score_range . 3 4 | 0.7711 | 0.110236 | . # tume max features param_tune = [] for i in [None, &#39;sqrt&#39;, &#39;log2&#39;]: rfc = ensemble.RandomForestClassifier(n_estimators=38, max_depth=7, max_features=i) rfc.fit(X, y) score = cross_val_score(rfc, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] param_tune . parameter mean_score score_range . 0 None | 0.758477 | 0.102362 | . 1 sqrt | 0.763220 | 0.094488 | . 2 log2 | 0.765570 | 0.110236 | . #collapse # tune min sample leaf param_tune = [] for i in np.arange(1, 100, 5): rfc = ensemble.RandomForestClassifier(n_estimators=38, max_depth=7, max_features=&#39;log2&#39;, min_samples_leaf=i) rfc.fit(X, y) score = cross_val_score(rfc, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;Min Sample Leaf&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;Min Sample Leaf&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . param_tune[param_tune[&#39;mean_score&#39;] == param_tune[&#39;mean_score&#39;].max()] . parameter mean_score score_range . 2 11 | 0.771097 | 0.098425 | . start_time = time.clock() rfc = ensemble.RandomForestClassifier(n_estimators=38, max_depth=7, max_features=&#39;log2&#39;, min_samples_leaf=1) y_pred = rfc.fit(X_train, y_train).predict(X_test) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) confusion_matrix(y_test, y_pred) . Runtime: 0.08 seconds . array([[276, 101], [ 86, 298]], dtype=int64) . cv_score =cross_val_score(rfc, X, y, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.81889764 0.77952756 0.74015748 0.74409449 0.7992126 0.72834646 0.72834646 0.76190476 0.75793651 0.79365079] cross validation mean: 0.7652074740657417 cross validation range: 0.09055118110236215 . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 101 Type 2 error (false negative): 86 Sensitivity: 0.7760416666666666 Specificity: 0.7320954907161804 . Logistic Regression . start_time = time.clock() lr = LogisticRegression(C=1e9) fit = lr.fit(X_train, y_train) # Display. print(&#39;Coefficients&#39;) print(fit.coef_) print(fit.intercept_) y_pred = lr.predict(X_test) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) print(&#39; n Percentage accuracy&#39;) print(lr.score(X_test, y_test)) confusion_matrix(y_test, y_pred) . Coefficients [[-5.48136284e-02 1.85738874e-02 2.38236647e-04 7.90269932e-03 -3.44876396e-01 2.10628828e-02 4.30025222e-02 3.05330675e-01 -4.61161690e-02 -4.61161690e-02 -1.66099696e-01 -4.61161690e-02 -1.99402439e-01 -4.61161690e-02 -1.02945652e-01 -4.61161690e-02 -5.06969766e-01 -4.61161690e-02 4.30702452e-02 -4.61161690e-02 1.53784545e-01 -6.78859682e-01 -1.31429256e+00 3.61629902e-01 -4.18411418e-01 1.75669055e-01 -1.48340302e-01]] [-0.08964106] Runtime: 0.02 seconds Percentage accuracy 0.7490144546649146 . array([[277, 100], [ 91, 293]], dtype=int64) . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 100 Type 2 error (false negative): 91 Sensitivity: 0.7630208333333334 Specificity: 0.7347480106100795 . feature_rank = pd.DataFrame({&#39;features&#39;: X.columns, &#39;coefficients&#39;: fit.coef_.flatten()}) feature_rank[&#39;absolute_coef&#39;] = feature_rank[&#39;coefficients&#39;].abs() feature_rank.sort_values(by=[&#39;absolute_coef&#39;], inplace=True, ascending=False) feature_rank = feature_rank.reset_index(drop=True) feature_rank . features coefficients absolute_coef . 0 Contract_Two year | -1.314293 | 1.314293 | . 1 Contract_One year | -0.678860 | 0.678860 | . 2 TechSupport_Yes | -0.506970 | 0.506970 | . 3 PaymentMethod_Credit card (automatic) | -0.418411 | 0.418411 | . 4 PaperlessBilling_Yes | 0.361630 | 0.361630 | . 5 Partner_Yes | -0.344876 | 0.344876 | . 6 InternetService_Fiber optic | 0.305331 | 0.305331 | . 7 OnlineBackup_Yes | -0.199402 | 0.199402 | . 8 PaymentMethod_Electronic check | 0.175669 | 0.175669 | . 9 OnlineSecurity_Yes | -0.166100 | 0.166100 | . 10 StreamingMovies_Yes | 0.153785 | 0.153785 | . 11 PaymentMethod_Mailed check | -0.148340 | 0.148340 | . 12 DeviceProtection_Yes | -0.102946 | 0.102946 | . 13 tenure | -0.054814 | 0.054814 | . 14 TechSupport_No internet service | -0.046116 | 0.046116 | . 15 OnlineBackup_No internet service | -0.046116 | 0.046116 | . 16 StreamingTV_No internet service | -0.046116 | 0.046116 | . 17 StreamingMovies_No internet service | -0.046116 | 0.046116 | . 18 OnlineSecurity_No internet service | -0.046116 | 0.046116 | . 19 InternetService_No | -0.046116 | 0.046116 | . 20 DeviceProtection_No internet service | -0.046116 | 0.046116 | . 21 StreamingTV_Yes | 0.043070 | 0.043070 | . 22 MultipleLines_Yes | 0.043003 | 0.043003 | . 23 Dependents_Yes | 0.021063 | 0.021063 | . 24 MonthlyCharges | 0.018574 | 0.018574 | . 25 gender_Male | 0.007903 | 0.007903 | . 26 TotalCharges | 0.000238 | 0.000238 | . cv_score =cross_val_score(lr, X, y, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.81496063 0.79527559 0.75590551 0.73622047 0.7992126 0.74015748 0.72047244 0.71825397 0.73809524 0.76190476] cross validation mean: 0.7580458692663417 cross validation range: 0.09670666166729158 . from sklearn.feature_selection import RFE # Pass any estimator to the RFE constructor selector = RFE(lr) selector = selector.fit(X, y) rankings = pd.DataFrame({&#39;Features&#39;: X.columns, &#39;Ranking&#39; : selector.ranking_}) rankings.sort_values(&#39;Ranking&#39;) . Features Ranking . 26 PaymentMethod_Mailed check | 1 | . 22 Contract_Two year | 1 | . 21 Contract_One year | 1 | . 20 StreamingMovies_Yes | 1 | . 4 Partner_Yes | 1 | . 19 StreamingMovies_No internet service | 1 | . 17 StreamingTV_No internet service | 1 | . 7 InternetService_Fiber optic | 1 | . 16 TechSupport_Yes | 1 | . 15 TechSupport_No internet service | 1 | . 10 OnlineSecurity_Yes | 1 | . 25 PaymentMethod_Electronic check | 1 | . 12 OnlineBackup_Yes | 1 | . 13 DeviceProtection_No internet service | 2 | . 23 PaperlessBilling_Yes | 3 | . 11 OnlineBackup_No internet service | 4 | . 24 PaymentMethod_Credit card (automatic) | 5 | . 9 OnlineSecurity_No internet service | 6 | . 8 InternetService_No | 7 | . 18 StreamingTV_Yes | 8 | . 6 MultipleLines_Yes | 9 | . 0 tenure | 10 | . 14 DeviceProtection_Yes | 11 | . 1 MonthlyCharges | 12 | . 5 Dependents_Yes | 13 | . 3 gender_Male | 14 | . 2 TotalCharges | 15 | . Logistic Regression with Ridge Regularization . #collapse # tune l2 regularization param_tune = [] for i in [0.000001, 0.00001, 0.0001, 0.001, 0.0015, 0.003, 0.006, 0.01, 0.02, 0.05, 0.07, 0.09, 0.1, 0.5]: #for i in [0.001, 0.0015, 0.002, 0.0025, 0.003, 0.0035, 0.004, 0.0045, 0.005, 0.0055, 0.006, 0.01]: ridge = LogisticRegression(penalty=&#39;l2&#39;, C=i) ridge.fit(X, y) score = cross_val_score(ridge, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;C Parameter&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;C Parameter&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . param_tune[param_tune[&#39;mean_score&#39;] == param_tune[&#39;mean_score&#39;].max()] . parameter mean_score score_range . 12 0.1 | 0.759243 | 0.088833 | . start_time = time.clock() ridge = LogisticRegression(penalty=&#39;l2&#39;, C=0.01) fit = ridge.fit(X_train, y_train) # Display. print(&#39;Coefficients&#39;) print(fit.coef_) print(fit.intercept_) y_pred = ridge.predict(X_test) print(&#39; n Percentage accuracy&#39;) print(ridge.score(X_test, y_test)) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) confusion_matrix(y_test, y_pred) . Coefficients [[-0.0730773 0.02146744 0.00027319 -0.0180065 -0.12632967 -0.07406468 0.04230398 0.14478864 -0.0552993 -0.0552993 -0.13255568 -0.0552993 -0.08312377 -0.0552993 -0.07375451 -0.0552993 -0.24009355 -0.0552993 0.0014158 -0.0552993 0.01862043 -0.11838612 -0.18503894 0.16492533 -0.12816655 0.15927478 -0.08137516]] [-0.0567018] Percentage accuracy 0.7371879106438897 Runtime: 0.02 seconds . array([[282, 95], [105, 279]], dtype=int64) . cv_score =cross_val_score(ridge, X, y, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.7992126 0.77559055 0.7519685 0.71653543 0.77952756 0.71259843 0.72440945 0.71825397 0.73809524 0.78571429] cross validation mean: 0.7501906011748531 cross validation range: 0.08661417322834652 . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 95 Type 2 error (false negative): 105 Sensitivity: 0.7265625 Specificity: 0.7480106100795756 . Logistic Regression with Lasso Regularization . #collapse # tune l1 regularization param_tune = [] for i in [0.000001, 0.00001, 0.0001, 0.001, 0.001, 0.01, 0.015, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.2, 0.25]: lasso = LogisticRegression(penalty=&#39;l1&#39;, C=i) lasso.fit(X, y) score = cross_val_score(lasso, X, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;C Parameter&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;C Parameter&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . param_tune . parameter mean_score score_range . 0 0.000001 | 0.500000 | 0.000000 | . 1 0.000010 | 0.500000 | 0.000000 | . 2 0.000100 | 0.669679 | 0.066929 | . 3 0.001000 | 0.729681 | 0.078740 | . 4 0.001000 | 0.729284 | 0.078740 | . 5 0.010000 | 0.737183 | 0.057399 | . 6 0.015000 | 0.736789 | 0.057399 | . 7 0.100000 | 0.758858 | 0.092770 | . 8 0.110000 | 0.760830 | 0.100644 | . 9 0.120000 | 0.760027 | 0.116454 | . 10 0.130000 | 0.759633 | 0.112517 | . 11 0.140000 | 0.759236 | 0.108549 | . 12 0.150000 | 0.760417 | 0.108549 | . 13 0.200000 | 0.761202 | 0.108549 | . 14 0.250000 | 0.760802 | 0.108580 | . start_time = time.clock() lasso = LogisticRegression(penalty=&#39;l1&#39;, C=0.01) fit = lasso.fit(X_test, y_test) # Display. print(&#39;Coefficients&#39;) print(fit.coef_) print(fit.intercept_) y_pred = lasso.predict(X_test) print(&#39; n Percentage accuracy&#39;) print(lasso.score(X_test, y_test)) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) confusion_matrix(y_test, y_pred) . Coefficients [[-0.09030705 0.02106864 0.00045953 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ]] [0.] Percentage accuracy 0.721419185282523 Runtime: 0.01 seconds . array([[250, 127], [ 85, 299]], dtype=int64) . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 127 Type 2 error (false negative): 85 Sensitivity: 0.7786458333333334 Specificity: 0.6631299734748011 . cv_score =cross_val_score(lasso, X, y, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.76771654 0.7519685 0.72440945 0.72834646 0.7480315 0.71653543 0.71259843 0.71031746 0.75 0.76190476] cross validation mean: 0.737182852143482 cross validation range: 0.05739907511561049 . feature_rank = pd.DataFrame({&#39;features&#39;: X.columns, &#39;coefficients&#39;: fit.coef_.flatten()}) feature_rank[&#39;absolute_coef&#39;] = feature_rank[&#39;coefficients&#39;].abs() feature_rank.sort_values(by=[&#39;absolute_coef&#39;], inplace=True, ascending=False) feature_rank = feature_rank.reset_index(drop=True) feature_rank . features coefficients absolute_coef . 0 tenure | -0.090061 | 0.090061 | . 1 MonthlyCharges | 0.021067 | 0.021067 | . 2 TotalCharges | 0.000457 | 0.000457 | . 3 TechSupport_No internet service | 0.000000 | 0.000000 | . 4 PaymentMethod_Electronic check | 0.000000 | 0.000000 | . 5 PaymentMethod_Credit card (automatic) | 0.000000 | 0.000000 | . 6 PaperlessBilling_Yes | 0.000000 | 0.000000 | . 7 Contract_Two year | 0.000000 | 0.000000 | . 8 Contract_One year | 0.000000 | 0.000000 | . 9 StreamingMovies_Yes | 0.000000 | 0.000000 | . 10 StreamingMovies_No internet service | 0.000000 | 0.000000 | . 11 StreamingTV_Yes | 0.000000 | 0.000000 | . 12 StreamingTV_No internet service | 0.000000 | 0.000000 | . 13 TechSupport_Yes | 0.000000 | 0.000000 | . 14 DeviceProtection_No internet service | 0.000000 | 0.000000 | . 15 DeviceProtection_Yes | 0.000000 | 0.000000 | . 16 OnlineBackup_Yes | 0.000000 | 0.000000 | . 17 OnlineBackup_No internet service | 0.000000 | 0.000000 | . 18 OnlineSecurity_Yes | 0.000000 | 0.000000 | . 19 OnlineSecurity_No internet service | 0.000000 | 0.000000 | . 20 InternetService_No | 0.000000 | 0.000000 | . 21 InternetService_Fiber optic | 0.000000 | 0.000000 | . 22 MultipleLines_Yes | 0.000000 | 0.000000 | . 23 Dependents_Yes | 0.000000 | 0.000000 | . 24 Partner_Yes | 0.000000 | 0.000000 | . 25 gender_Male | 0.000000 | 0.000000 | . 26 PaymentMethod_Mailed check | 0.000000 | 0.000000 | . Using Lasso for Feature selection . X_lasso = X[[&#39;tenure&#39;, &#39;MonthlyCharges&#39;, &#39;TotalCharges&#39;]] . #collapse # tune l1 regularization param_tune = [] for i in [0.000001, 0.00001, 0.0001, 0.001, 0.001, 0.01, 0.015, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.2, 0.25]: lasso = LogisticRegression(penalty=&#39;l1&#39;, C=i) score = cross_val_score(lasso, X_lasso, y, cv=10) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;C Parameter&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;C Parameter&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . cv_score =cross_val_score(lasso, X_lasso, y, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.76771654 0.7519685 0.72440945 0.72834646 0.7480315 0.71653543 0.71259843 0.71031746 0.75 0.76190476] cross validation mean: 0.737182852143482 cross validation range: 0.05739907511561049 . SVM . #collapse # tune C parameter param_tune = [] #for i in [0.000001, 0.00001, 0.0001, 0.001, 0.001, 0.01, 0.015, 0.1, 0.15, .2, .3, .4, .5, .6, .7, .8, .9, 1, 2, 3, 4, 5, 10]: #for i in [0.01, 0.015, .05, 0.1, 0.15, .2, .25, .3, .35, .4, .45, .5, .55, .6, .65, .7, .75, .8, .85, .9, .95, 1]: for i in [.6, .7, .8, .9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]: svm = SVC(C=i, kernel=&#39;linear&#39;) score = cross_val_score(svm, X, y, cv=5) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;C Parameter&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;C Parameter&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . param_tune[param_tune[&#39;mean_score&#39;] == param_tune[&#39;mean_score&#39;].max()] . parameter mean_score score_range . 8 1.4 | 0.755706 | 0.074803 | . param_tune[param_tune[&#39;score_range&#39;] == param_tune[&#39;score_range&#39;].min()] . parameter mean_score score_range . 5 1.1 | 0.752952 | 0.043307 | . # tune #param_tune = [] #for i in [&#39;linear&#39;, &#39;poly&#39;, &#39;rbf&#39;]: # svm = SVC(C=.9, kernel=i) # svm.fit(X, y) # score = cross_val_score(svm, X, y, cv=5) # mean_score = score.mean() # score_range = score.max() - score.min() # param_tune.append([i, mean_score, score_range]) #param_tune = pd.DataFrame(param_tune) #param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] #param_tune . y_1d = df_downsampled[&#39;Churn&#39;] def svc_param_selection(X, y, nfolds): Cs = [0.001, 0.01, 0.1, 0.85, 1, 10] gammas = [0.001, 0.01, 0.1, 1] param_grid = {&#39;C&#39;: Cs, &#39;gamma&#39; : gammas} grid_search = GridSearchCV(SVC(kernel=&#39;rbf&#39;), param_grid, cv=nfolds) grid_search.fit(X, y) grid_search.best_params_ return grid_search.grid_scores_ . svc_param_selection(X, y_1d, 5) . svm = SVC(C=1, kernel=&#39;rbf&#39;, gamma=0.01) cross_val_score(svm, X, y, cv=5) . start_time = time.clock() svm = SVC(C=1.1, kernel=&#39;linear&#39;) y_pred = svm.fit(X_train, y_train).predict(X_test) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) confusion_matrix(y_test, y_pred) . Runtime: 407.72 seconds . array([[303, 74], [130, 254]], dtype=int64) . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 74 Type 2 error (false negative): 130 Sensitivity: 0.6614583333333334 Specificity: 0.8037135278514589 . cv_score =cross_val_score(svm, X, y, cv=5) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.77952756 0.73622047 0.7687747 0.74110672 0.73913043] cross validation mean: 0.7529519778407145 cross validation range: 0.04330708661417315 . svm = SVC(C=1.1, kernel=&#39;linear&#39;) cross_val_score(svm, X, y, cv=5) . array([0.78543307, 0.74015748, 0.75296443, 0.74703557, 0.73320158]) . Gradient Boost . #collapse # tune n_estimators param_tune = [] for i in np.arange(1, 150): boost = GradientBoostingClassifier(learning_rate=0.1, n_estimators=i, max_depth=8, min_samples_split=450, min_samples_leaf=42,max_features=&#39;sqrt&#39;,subsample=0.7) score = cross_val_score(boost, X, y, cv=5) mean_score = score.mean() score_range = score.max() - score.min() param_tune.append([i, mean_score, score_range]) param_tune = pd.DataFrame(param_tune) param_tune.columns = [&#39;parameter&#39;, &#39;mean_score&#39;, &#39;score_range&#39;] plt.figure(figsize=(12,5)) plt.subplot(1, 2, 1) plt.plot(param_tune.parameter, param_tune.mean_score) plt.title(&#39;mean cross val score&#39;) plt.xlabel(&#39;Number of Estimators&#39;) plt.ylabel(&#39;Mean Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(param_tune.parameter, param_tune.score_range) plt.title(&#39;cross val range&#39;) plt.xlabel(&#39;Number of Estimators&#39;) plt.ylabel(&#39;Score Range&#39;) plt.show() . . param_tune[param_tune[&#39;score_range&#39;] == param_tune[&#39;score_range&#39;].min()] . parameter mean_score score_range . 66 67 | 0.771485 | 0.046233 | . y_1d = df_downsampled[&#39;Churn&#39;] # Find number of estimators param_test1 = {&#39;max_depth&#39;: np.arange(2,16)} gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=67, min_samples_split=500,min_samples_leaf=50,max_features=&#39;sqrt&#39;,subsample=0.8), param_grid = param_test1, scoring=&#39;accuracy&#39;,n_jobs=4,iid=False, cv=5) gsearch1.fit(X,y_1d) gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_ . ([mean: 0.77148, std: 0.02084, params: {&#39;max_depth&#39;: 2}, mean: 0.77187, std: 0.02113, params: {&#39;max_depth&#39;: 3}, mean: 0.77109, std: 0.02097, params: {&#39;max_depth&#39;: 4}, mean: 0.76477, std: 0.02444, params: {&#39;max_depth&#39;: 5}, mean: 0.77306, std: 0.02390, params: {&#39;max_depth&#39;: 6}, mean: 0.76990, std: 0.01961, params: {&#39;max_depth&#39;: 7}, mean: 0.76990, std: 0.02018, params: {&#39;max_depth&#39;: 8}, mean: 0.76674, std: 0.02340, params: {&#39;max_depth&#39;: 9}, mean: 0.76832, std: 0.02356, params: {&#39;max_depth&#39;: 10}, mean: 0.77069, std: 0.02332, params: {&#39;max_depth&#39;: 11}, mean: 0.76950, std: 0.02459, params: {&#39;max_depth&#39;: 12}, mean: 0.77109, std: 0.02131, params: {&#39;max_depth&#39;: 13}, mean: 0.77147, std: 0.02411, params: {&#39;max_depth&#39;: 14}, mean: 0.77266, std: 0.02601, params: {&#39;max_depth&#39;: 15}], {&#39;max_depth&#39;: 6}, 0.7730556160717064) . param_test2 = {&#39;min_samples_split&#39;: np.arange(50,1001,10)} gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=67, max_depth=8, min_samples_leaf=50, max_features=&#39;sqrt&#39;, subsample=0.7), param_grid = param_test2, scoring=&#39;accuracy&#39;, n_jobs=4, iid=False, cv=5) gsearch2.fit(X,y_1d) gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_ . ([mean: 0.76240, std: 0.02630, params: {&#39;min_samples_split&#39;: 50}, mean: 0.76319, std: 0.02516, params: {&#39;min_samples_split&#39;: 60}, mean: 0.76675, std: 0.02085, params: {&#39;min_samples_split&#39;: 70}, mean: 0.76202, std: 0.01974, params: {&#39;min_samples_split&#39;: 80}, mean: 0.76477, std: 0.02221, params: {&#39;min_samples_split&#39;: 90}, mean: 0.76517, std: 0.01977, params: {&#39;min_samples_split&#39;: 100}, mean: 0.76438, std: 0.02166, params: {&#39;min_samples_split&#39;: 110}, mean: 0.76832, std: 0.02396, params: {&#39;min_samples_split&#39;: 120}, mean: 0.76990, std: 0.02191, params: {&#39;min_samples_split&#39;: 130}, mean: 0.76556, std: 0.02003, params: {&#39;min_samples_split&#39;: 140}, mean: 0.76674, std: 0.01984, params: {&#39;min_samples_split&#39;: 150}, mean: 0.76990, std: 0.02191, params: {&#39;min_samples_split&#39;: 160}, mean: 0.75806, std: 0.02320, params: {&#39;min_samples_split&#39;: 170}, mean: 0.76241, std: 0.02014, params: {&#39;min_samples_split&#39;: 180}, mean: 0.76359, std: 0.02043, params: {&#39;min_samples_split&#39;: 190}, mean: 0.76161, std: 0.02059, params: {&#39;min_samples_split&#39;: 200}, mean: 0.76872, std: 0.02358, params: {&#39;min_samples_split&#39;: 210}, mean: 0.76912, std: 0.01839, params: {&#39;min_samples_split&#39;: 220}, mean: 0.77029, std: 0.02164, params: {&#39;min_samples_split&#39;: 230}, mean: 0.76794, std: 0.01711, params: {&#39;min_samples_split&#39;: 240}, mean: 0.76241, std: 0.01687, params: {&#39;min_samples_split&#39;: 250}, mean: 0.76991, std: 0.02069, params: {&#39;min_samples_split&#39;: 260}, mean: 0.76715, std: 0.02004, params: {&#39;min_samples_split&#39;: 270}, mean: 0.76872, std: 0.01981, params: {&#39;min_samples_split&#39;: 280}, mean: 0.76319, std: 0.02297, params: {&#39;min_samples_split&#39;: 290}, mean: 0.77306, std: 0.01875, params: {&#39;min_samples_split&#39;: 300}, mean: 0.77109, std: 0.02038, params: {&#39;min_samples_split&#39;: 310}, mean: 0.76872, std: 0.01801, params: {&#39;min_samples_split&#39;: 320}, mean: 0.76557, std: 0.01833, params: {&#39;min_samples_split&#39;: 330}, mean: 0.77030, std: 0.01713, params: {&#39;min_samples_split&#39;: 340}, mean: 0.76753, std: 0.02210, params: {&#39;min_samples_split&#39;: 350}, mean: 0.76990, std: 0.02021, params: {&#39;min_samples_split&#39;: 360}, mean: 0.76991, std: 0.02190, params: {&#39;min_samples_split&#39;: 370}, mean: 0.76910, std: 0.02153, params: {&#39;min_samples_split&#39;: 380}, mean: 0.76872, std: 0.01986, params: {&#39;min_samples_split&#39;: 390}, mean: 0.77030, std: 0.02021, params: {&#39;min_samples_split&#39;: 400}, mean: 0.76675, std: 0.02144, params: {&#39;min_samples_split&#39;: 410}, mean: 0.76911, std: 0.02144, params: {&#39;min_samples_split&#39;: 420}, mean: 0.77227, std: 0.01911, params: {&#39;min_samples_split&#39;: 430}, mean: 0.76556, std: 0.01920, params: {&#39;min_samples_split&#39;: 440}, mean: 0.76713, std: 0.02831, params: {&#39;min_samples_split&#39;: 450}, mean: 0.76753, std: 0.02374, params: {&#39;min_samples_split&#39;: 460}, mean: 0.77149, std: 0.02054, params: {&#39;min_samples_split&#39;: 470}, mean: 0.76911, std: 0.02230, params: {&#39;min_samples_split&#39;: 480}, mean: 0.76753, std: 0.02417, params: {&#39;min_samples_split&#39;: 490}, mean: 0.76990, std: 0.01796, params: {&#39;min_samples_split&#39;: 500}, mean: 0.76871, std: 0.02533, params: {&#39;min_samples_split&#39;: 510}, mean: 0.76952, std: 0.02284, params: {&#39;min_samples_split&#39;: 520}, mean: 0.77346, std: 0.02176, params: {&#39;min_samples_split&#39;: 530}, mean: 0.76833, std: 0.01973, params: {&#39;min_samples_split&#39;: 540}, mean: 0.77109, std: 0.02111, params: {&#39;min_samples_split&#39;: 550}, mean: 0.77109, std: 0.01780, params: {&#39;min_samples_split&#39;: 560}, mean: 0.76752, std: 0.02408, params: {&#39;min_samples_split&#39;: 570}, mean: 0.77424, std: 0.02288, params: {&#39;min_samples_split&#39;: 580}, mean: 0.76990, std: 0.02131, params: {&#39;min_samples_split&#39;: 590}, mean: 0.77109, std: 0.02057, params: {&#39;min_samples_split&#39;: 600}, mean: 0.77307, std: 0.02679, params: {&#39;min_samples_split&#39;: 610}, mean: 0.77030, std: 0.02277, params: {&#39;min_samples_split&#39;: 620}, mean: 0.77543, std: 0.02782, params: {&#39;min_samples_split&#39;: 630}, mean: 0.77267, std: 0.02144, params: {&#39;min_samples_split&#39;: 640}, mean: 0.77463, std: 0.02300, params: {&#39;min_samples_split&#39;: 650}, mean: 0.77426, std: 0.02223, params: {&#39;min_samples_split&#39;: 660}, mean: 0.77306, std: 0.02229, params: {&#39;min_samples_split&#39;: 670}, mean: 0.77346, std: 0.02215, params: {&#39;min_samples_split&#39;: 680}, mean: 0.77108, std: 0.02528, params: {&#39;min_samples_split&#39;: 690}, mean: 0.77109, std: 0.02005, params: {&#39;min_samples_split&#39;: 700}, mean: 0.77267, std: 0.02272, params: {&#39;min_samples_split&#39;: 710}, mean: 0.77385, std: 0.02344, params: {&#39;min_samples_split&#39;: 720}, mean: 0.76872, std: 0.02351, params: {&#39;min_samples_split&#39;: 730}, mean: 0.76950, std: 0.02614, params: {&#39;min_samples_split&#39;: 740}, mean: 0.77267, std: 0.02060, params: {&#39;min_samples_split&#39;: 750}, mean: 0.76951, std: 0.02286, params: {&#39;min_samples_split&#39;: 760}, mean: 0.77385, std: 0.01831, params: {&#39;min_samples_split&#39;: 770}, mean: 0.76990, std: 0.02414, params: {&#39;min_samples_split&#39;: 780}, mean: 0.77187, std: 0.02162, params: {&#39;min_samples_split&#39;: 790}, mean: 0.76951, std: 0.01967, params: {&#39;min_samples_split&#39;: 800}, mean: 0.77068, std: 0.02717, params: {&#39;min_samples_split&#39;: 810}, mean: 0.76872, std: 0.01971, params: {&#39;min_samples_split&#39;: 820}, mean: 0.76832, std: 0.02434, params: {&#39;min_samples_split&#39;: 830}, mean: 0.77226, std: 0.02556, params: {&#39;min_samples_split&#39;: 840}, mean: 0.76950, std: 0.02416, params: {&#39;min_samples_split&#39;: 850}, mean: 0.77148, std: 0.02237, params: {&#39;min_samples_split&#39;: 860}, mean: 0.76595, std: 0.02473, params: {&#39;min_samples_split&#39;: 870}, mean: 0.76832, std: 0.02737, params: {&#39;min_samples_split&#39;: 880}, mean: 0.77029, std: 0.02347, params: {&#39;min_samples_split&#39;: 890}, mean: 0.76793, std: 0.02533, params: {&#39;min_samples_split&#39;: 900}, mean: 0.76714, std: 0.02468, params: {&#39;min_samples_split&#39;: 910}, mean: 0.77030, std: 0.02175, params: {&#39;min_samples_split&#39;: 920}, mean: 0.77149, std: 0.02137, params: {&#39;min_samples_split&#39;: 930}, mean: 0.77188, std: 0.02495, params: {&#39;min_samples_split&#39;: 940}, mean: 0.76674, std: 0.02619, params: {&#39;min_samples_split&#39;: 950}, mean: 0.76951, std: 0.02370, params: {&#39;min_samples_split&#39;: 960}, mean: 0.77069, std: 0.02673, params: {&#39;min_samples_split&#39;: 970}, mean: 0.76438, std: 0.01878, params: {&#39;min_samples_split&#39;: 980}, mean: 0.77069, std: 0.02468, params: {&#39;min_samples_split&#39;: 990}, mean: 0.76596, std: 0.02744, params: {&#39;min_samples_split&#39;: 1000}], {&#39;min_samples_split&#39;: 630}, 0.7754256014440882) . param_test3 = {&#39;min_samples_leaf&#39;: np.arange(20,71)} gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500, n_estimators=67, max_depth=8, max_features=&#39;sqrt&#39;, subsample=0.7), param_grid = param_test3, scoring=&#39;accuracy&#39;, n_jobs=4, iid=False, cv=5) gsearch3.fit(X,y_1d) gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_ . ([mean: 0.76675, std: 0.01931, params: {&#39;min_samples_leaf&#39;: 20}, mean: 0.77543, std: 0.02090, params: {&#39;min_samples_leaf&#39;: 21}, mean: 0.77267, std: 0.02630, params: {&#39;min_samples_leaf&#39;: 22}, mean: 0.76793, std: 0.01852, params: {&#39;min_samples_leaf&#39;: 23}, mean: 0.77109, std: 0.02280, params: {&#39;min_samples_leaf&#39;: 24}, mean: 0.76911, std: 0.02234, params: {&#39;min_samples_leaf&#39;: 25}, mean: 0.77267, std: 0.02083, params: {&#39;min_samples_leaf&#39;: 26}, mean: 0.77187, std: 0.02100, params: {&#39;min_samples_leaf&#39;: 27}, mean: 0.76556, std: 0.01997, params: {&#39;min_samples_leaf&#39;: 28}, mean: 0.77030, std: 0.01830, params: {&#39;min_samples_leaf&#39;: 29}, mean: 0.76873, std: 0.01373, params: {&#39;min_samples_leaf&#39;: 30}, mean: 0.76675, std: 0.02054, params: {&#39;min_samples_leaf&#39;: 31}, mean: 0.76596, std: 0.02018, params: {&#39;min_samples_leaf&#39;: 32}, mean: 0.77148, std: 0.02205, params: {&#39;min_samples_leaf&#39;: 33}, mean: 0.76832, std: 0.02413, params: {&#39;min_samples_leaf&#39;: 34}, mean: 0.76754, std: 0.02430, params: {&#39;min_samples_leaf&#39;: 35}, mean: 0.77346, std: 0.02674, params: {&#39;min_samples_leaf&#39;: 36}, mean: 0.77464, std: 0.02437, params: {&#39;min_samples_leaf&#39;: 37}, mean: 0.76832, std: 0.02347, params: {&#39;min_samples_leaf&#39;: 38}, mean: 0.76992, std: 0.01638, params: {&#39;min_samples_leaf&#39;: 39}, mean: 0.76832, std: 0.02419, params: {&#39;min_samples_leaf&#39;: 40}, mean: 0.76951, std: 0.02164, params: {&#39;min_samples_leaf&#39;: 41}, mean: 0.77147, std: 0.02387, params: {&#39;min_samples_leaf&#39;: 42}, mean: 0.77110, std: 0.02044, params: {&#39;min_samples_leaf&#39;: 43}, mean: 0.76950, std: 0.01913, params: {&#39;min_samples_leaf&#39;: 44}, mean: 0.77464, std: 0.02083, params: {&#39;min_samples_leaf&#39;: 45}, mean: 0.76635, std: 0.02680, params: {&#39;min_samples_leaf&#39;: 46}, mean: 0.77188, std: 0.01980, params: {&#39;min_samples_leaf&#39;: 47}, mean: 0.77147, std: 0.02279, params: {&#39;min_samples_leaf&#39;: 48}, mean: 0.77188, std: 0.02139, params: {&#39;min_samples_leaf&#39;: 49}, mean: 0.77148, std: 0.02149, params: {&#39;min_samples_leaf&#39;: 50}, mean: 0.76911, std: 0.02432, params: {&#39;min_samples_leaf&#39;: 51}, mean: 0.77345, std: 0.01780, params: {&#39;min_samples_leaf&#39;: 52}, mean: 0.77187, std: 0.02291, params: {&#39;min_samples_leaf&#39;: 53}, mean: 0.76912, std: 0.02122, params: {&#39;min_samples_leaf&#39;: 54}, mean: 0.77267, std: 0.02095, params: {&#39;min_samples_leaf&#39;: 55}, mean: 0.76950, std: 0.02128, params: {&#39;min_samples_leaf&#39;: 56}, mean: 0.77109, std: 0.01949, params: {&#39;min_samples_leaf&#39;: 57}, mean: 0.77306, std: 0.02247, params: {&#39;min_samples_leaf&#39;: 58}, mean: 0.76991, std: 0.02141, params: {&#39;min_samples_leaf&#39;: 59}, mean: 0.77424, std: 0.02200, params: {&#39;min_samples_leaf&#39;: 60}, mean: 0.76753, std: 0.01937, params: {&#39;min_samples_leaf&#39;: 61}, mean: 0.77069, std: 0.02299, params: {&#39;min_samples_leaf&#39;: 62}, mean: 0.77306, std: 0.02385, params: {&#39;min_samples_leaf&#39;: 63}, mean: 0.76990, std: 0.01979, params: {&#39;min_samples_leaf&#39;: 64}, mean: 0.76635, std: 0.01941, params: {&#39;min_samples_leaf&#39;: 65}, mean: 0.76595, std: 0.02140, params: {&#39;min_samples_leaf&#39;: 66}, mean: 0.76951, std: 0.02113, params: {&#39;min_samples_leaf&#39;: 67}, mean: 0.77148, std: 0.02399, params: {&#39;min_samples_leaf&#39;: 68}, mean: 0.77069, std: 0.01999, params: {&#39;min_samples_leaf&#39;: 69}, mean: 0.77149, std: 0.01732, params: {&#39;min_samples_leaf&#39;: 70}], {&#39;min_samples_leaf&#39;: 21}, 0.7754318259624662) . param_test5 = {&#39;subsample&#39;:[0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1]} gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=67,max_depth=8,min_samples_split=500, min_samples_leaf=21,max_features=&#39;sqrt&#39;), param_grid = param_test5, scoring=&#39;accuracy&#39;,n_jobs=4,iid=False, cv=5) gsearch5.fit(X,y_1d) gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_ . ([mean: 0.77069, std: 0.02196, params: {&#39;subsample&#39;: 0.5}, mean: 0.77306, std: 0.02383, params: {&#39;subsample&#39;: 0.55}, mean: 0.77030, std: 0.01948, params: {&#39;subsample&#39;: 0.6}, mean: 0.76911, std: 0.02229, params: {&#39;subsample&#39;: 0.65}, mean: 0.76990, std: 0.02330, params: {&#39;subsample&#39;: 0.7}, mean: 0.77345, std: 0.02310, params: {&#39;subsample&#39;: 0.75}, mean: 0.76990, std: 0.02041, params: {&#39;subsample&#39;: 0.8}, mean: 0.77069, std: 0.02443, params: {&#39;subsample&#39;: 0.85}, mean: 0.76359, std: 0.01912, params: {&#39;subsample&#39;: 0.9}, mean: 0.76792, std: 0.02551, params: {&#39;subsample&#39;: 0.95}, mean: 0.76674, std: 0.02233, params: {&#39;subsample&#39;: 1}], {&#39;subsample&#39;: 0.75}, 0.773449316859108) . start_time = time.clock() boost = GradientBoostingClassifier(learning_rate=0.1, n_estimators=67, max_depth=8, min_samples_split=500, min_samples_leaf=21,max_features=&#39;sqrt&#39;,subsample=0.75) y_pred = boost.fit(X_train, y_train).predict(X_test) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) confusion_matrix(y_test, y_pred) . Runtime: 0.11 seconds . array([[296, 81], [ 90, 294]], dtype=int64) . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 81 Type 2 error (false negative): 90 Sensitivity: 0.765625 Specificity: 0.7851458885941645 . y_1d = df_downsampled[&#39;Churn&#39;] cv_score =cross_val_score(boost, X, y_1d, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.83858268 0.7992126 0.7480315 0.77952756 0.81102362 0.7480315 0.74409449 0.78174603 0.75396825 0.79365079] cross validation mean: 0.7797869016372954 cross validation range: 0.0944881889763779 . Plot SHAP values for feature importance . import shap . shap_values = shap.TreeExplainer(boost).shap_values(X_train) shap.summary_plot(shap_values, X_train, plot_type=&quot;bar&quot;) . shap.summary_plot(shap_values, X_train) . shap.dependence_plot(&#39;tenure&#39;, shap_values, X_train) . PCA . Xt = X.T Cx = np.cov(Xt) #print(&#39;Covariance Matrix: n&#39;, Cx) eig_val_cov, eig_vec_cov = np.linalg.eig(Cx) plt.plot(eig_val_cov) plt.title(&#39;Explained Variance&#39;) plt.xlabel(&#39;Principal Components&#39;) plt.ylabel(&#39;Variance Explained&#39;) plt.xlim((0, 5)) plt.show() . pca = PCA(n_components=X.shape[1]) X_pca = pca.fit(X) plt.plot(X_pca.explained_variance_[3:]) plt.title(&#39;Explained Variance&#39;) plt.xlabel(&#39;Principal Components&#39;) plt.ylabel(&#39;Variance Explained&#39;) plt.show() . sklearn_pca = PCA(n_components=2) pca_components = sklearn_pca.fit_transform(X) . cv_score =cross_val_score(boost, pca_components, y_1d, cv=10) cv_range = cv_score.max() - cv_score.min() print(cv_score) print(&#39;cross validation mean: {}&#39;.format(cv_score.mean())) print(&#39;cross validation range: {}&#39;.format(cv_range)) . [0.77165354 0.76771654 0.74409449 0.74409449 0.76771654 0.71259843 0.73622047 0.75 0.74206349 0.75 ] cross validation mean: 0.7486157980252468 cross validation range: 0.05905511811023623 . # create training and testing vars with PCA components X_train, X_test, y_train, y_test = train_test_split(pca_components, y, test_size=0.3, random_state=1) y_test = y_test.flatten() . start_time = time.clock() boost = GradientBoostingClassifier(learning_rate=0.1, n_estimators=67, max_depth=8, min_samples_split=450, min_samples_leaf=42,max_features=&#39;sqrt&#39;,subsample=0.7) y_pred = boost.fit(X_train, y_train).predict(X_test) print(&#39; nRuntime: {} seconds&#39;.format(round((time.clock()-start_time),2))) confusion_matrix(y_test, y_pred) . Runtime: 0.08 seconds . array([[286, 91], [100, 284]], dtype=int64) . confusion = confusion_matrix(y_test, y_pred) print(&#39;Type 1 error (false positive): {}&#39;.format(confusion[0][1])) print(&#39;Type 2 error (false negative): {}&#39;.format(confusion[1][0])) print(&#39;Sensitivity: {}&#39;.format(confusion[1][1] / confusion[1].sum())) print(&#39;Specificity: {}&#39;.format(confusion[0][0] / confusion[0].sum())) . Type 1 error (false positive): 91 Type 2 error (false negative): 100 Sensitivity: 0.7395833333333334 Specificity: 0.7586206896551724 . Results . results = pd.read_csv(&#39;predicting_churn_results.csv&#39;) . results . model cross_val_mean cross_val_range type_1_error type_2_error sensitivity specificity run_time . 0 naive bayes | 0.717038 | 0.094488 | 165 | 51 | 0.867188 | 0.562334 | 0.01 | . 1 knn | 0.727722 | 0.059055 | 102 | 114 | 0.703125 | 0.729443 | 0.02 | . 2 decision tree | 0.722575 | 0.110236 | 72 | 152 | 0.604167 | 0.809019 | 0.01 | . 3 random forest | 0.765207 | 0.090551 | 101 | 86 | 0.776042 | 0.732095 | 0.08 | . 4 logistic regression | 0.758046 | 0.096707 | 100 | 91 | 0.763021 | 0.734748 | 0.02 | . 5 ridge logistic reg | 0.750191 | 0.086614 | 95 | 105 | 0.726562 | 0.748011 | 0.01 | . 6 lasso logistic reg | 0.737183 | 0.057399 | 127 | 85 | 0.778646 | 0.663130 | 0.01 | . 7 svm | 0.752952 | 0.043307 | 74 | 130 | 0.661458 | 0.803714 | 407.72 | . 8 gradient boosting | 0.773481 | 0.094488 | 86 | 90 | 0.765625 | 0.771883 | 0.10 | . 9 pca gradient boost | 0.748616 | 0.059055 | 91 | 100 | 0.739583 | 0.758621 | 0.08 | . palette = [&#39;#7f3b08&#39;,&#39;#b35806&#39;,&#39;#e08214&#39;,&#39;#fdb863&#39;,&#39;#fee0b6&#39;,&#39;#d8daeb&#39;,&#39;#b2abd2&#39;,&#39;#8073ac&#39;,&#39;#542788&#39;,&#39;#2d004b&#39;] sns.set_palette(palette) plt.figure(figsize=(14,5)) sns.barplot(x=&quot;model&quot;, y=&quot;cross_val_mean&quot;, data=results.sort_values(&#39;cross_val_mean&#39;)) plt.xticks(rotation=15) plt.ylim(.5, .8) plt.title(&#39;Cross Validation Score&#39;) plt.show() . plt.figure(figsize=(14,5)) sns.barplot(x=&quot;model&quot;, y=&quot;cross_val_range&quot;, data=results.sort_values(&#39;cross_val_mean&#39;)) plt.xticks(rotation=15) #plt.ylim(.5, .8) plt.title(&#39;Cross Validation Range&#39;) plt.show() . View on github .",
            "url": "http://www.datastuff.io/nlp/keras/deep%20learning/aws/2020/03/17/predicting-churn.html",
            "relUrl": "/nlp/keras/deep%20learning/aws/2020/03/17/predicting-churn.html",
            "date": " • Mar 17, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Loren Price . Data scientist and engineer based in Brooklyn, NY. . Purveyor of good data, bad stock art, and all things Arsenal F.C. . Contact: LORENJPRICE [at] GMAIL [dot] COM . Or visit me on Github .",
          "url": "http://www.datastuff.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "http://www.datastuff.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}